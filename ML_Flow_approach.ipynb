{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category                                            Message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with your actual dataset file)\n",
    "data = pd.read_csv('f:\\\\indira college hackathon\\\\email.csv')\n",
    "\n",
    "# Since PandasAI cannot be imported, we will skip its initialization and visualization\n",
    "# Instead, we can display the first few rows of the dataset as a simple visualization\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandasai\\pipelines\\chat\\generate_chat_pipeline.py\", line 335, in run\n",
      "    ).run(input)\n",
      "      ^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandasai\\pipelines\\pipeline.py\", line 137, in run\n",
      "    raise e\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandasai\\pipelines\\pipeline.py\", line 101, in run\n",
      "    step_output = logic.execute(\n",
      "                  ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandasai\\pipelines\\chat\\code_generator.py\", line 33, in execute\n",
      "    code = pipeline_context.config.llm.generate_code(input, pipeline_context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandasai\\llm\\base.py\", line 201, in generate_code\n",
      "    response = self.call(instruction, context)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandasai\\llm\\bamboo_llm.py\", line 18, in call\n",
      "    response = self._session.post(\"/llm/chat\", json=data)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandasai\\helpers\\request.py\", line 37, in post\n",
      "    return self.make_request(\"POST\", path, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandasai\\helpers\\request.py\", line 71, in make_request\n",
      "    raise PandasAIApiCallError(data[\"message\"])\n",
      "pandasai.exceptions.PandasAIApiCallError: Unauthorized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in APILogger: {\"message\":\"Invalid API Key!\",\"data\":null}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pandasai import Agent\n",
    "\n",
    "# Set the API key for PandasAI\n",
    "os.environ['PANDASAI_API_KEY'] = 'your_api_key_here'  # Replace 'your_api_key_here' with your actual API key\n",
    "\n",
    "# Create a DataFrame containing sales data by country\n",
    "sales_by_country = pd.DataFrame({\n",
    "    \"country\": [\"United States\", \"United Kingdom\", \"France\", \"Germany\", \"Italy\", \"Spain\", \"Canada\", \"Australia\", \"Japan\", \"China\"],\n",
    "    \"sales\": [5000, 3200, 2900, 4100, 2300, 2100, 2500, 2600, 4500, 7000]\n",
    "})\n",
    "\n",
    "# Initialize the PandasAI agent with the sales data\n",
    "agent = Agent(sales_by_country)\n",
    "\n",
    "# Use the agent to query the top 5 countries by sales\n",
    "top_countries = agent.chat('Which are the top 5 countries by sales?')\n",
    "# Expected Output: China, United States, Japan, Germany, Australia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6436bcfe6173417ea424f905758faec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = sales_by_country[['sales']]\n",
    "y = sales_by_country['country']\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Initialize and train the model\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Decode the predictions back to original labels\n",
    "    predictions_decoded = label_encoder.inverse_transform(predictions.astype(int))\n",
    "\n",
    "    # Calculate and log the mean squared error\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "    # Log the model with input example for signature inference\n",
    "    mlflow.sklearn.log_model(model, \"model\", input_example=X_test.iloc[0].to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production-grade issues faced by developers in building data pipelines include:\n",
    "\n",
    "\n",
    "# 1. Data Quality: Ensuring data consistency and integrity is crucial, as poor data quality can lead to inaccurate insights and decisions.\n",
    "# 2. Scalability: As data volumes grow, pipelines must efficiently scale to handle increased loads without performance degradation.\n",
    "# 3. Versioning: Managing versions of both data and models is essential to track changes and ensure reproducibility in experiments.\n",
    "# 4. Monitoring: Continuous monitoring of pipeline performance is necessary to detect and address issues in real-time, ensuring reliability.\n",
    "# 5. Collaboration: Effective collaboration among team members is vital, requiring tools that facilitate sharing of code, experiments, and results.\n",
    "\n",
    "\n",
    "# Strategies to address these production-grade issues using MLflow include:\n",
    "\n",
    "# 1. Data Quality: Implement logging capabilities in MLflow to track and validate data quality metrics.\n",
    "# 2. Scalability: Utilize MLflow's integration with cloud services to dynamically scale resources based on demand.\n",
    "# 3. Versioning: Leverage MLflow's model registry for effective management and versioning of models.\n",
    "# 4. Monitoring: Use MLflow's tracking server to log and monitor pipeline performance metrics.\n",
    "# 5. Collaboration: Employ MLflow's centralized tracking system to enhance team collaboration on experiments and results.\n",
    "\n",
    "# Example code to log data quality metrics and manage model versioning:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_data_quality_metrics(data):\n",
    "    # Function to log data quality metrics\n",
    "    missing_values = data.isnull().sum()\n",
    "    mlflow.log_metrics({\"missing_values\": missing_values.sum()})\n",
    "    \n",
    "    # Log additional data quality metrics\n",
    "    data_types = data.dtypes.to_dict()\n",
    "    mlflow.log_params({\"data_types\": data_types})\n",
    "\n",
    "# Call the function to log data quality metrics\n",
    "log_data_quality_metrics(sales_by_country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
